\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % IEEE conference format
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{array}

\title{\LARGE \bf
Clasificación Automática de Tumores Cerebrales en Imágenes MRI mediante Redes Neuronales Convolucionales
}

\author{Breitner Enrique Gonzalez Angarita \\ Jeferson David Vargas Toca}


\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}



\section{Introducción}

\subsection{Contexto y Justificación}

El diagnóstico temprano de tumores cerebrales es fundamental para un tratamiento oncológico eficaz. Las técnicas tradicionales de análisis de imágenes dependen de la experiencia del especialista, lo que puede generar variabiliad en los resultados. Los avances en \textit{deep learning} permiten automatizar este proceso, mejorando la precisión diagnóstica y optimizando el tiempo de análisis.

\subsection{Estado del Arte}

Los avances en \textit{deep learning} para el análisis de imágenes médicas han demostrado resultados prometedores. LeCun et al.~\cite{c1} establecieron los fundamentos del \textit{deep learning} moderno, mientras que He et al.~\cite{c2} introdujeron las \textit{redes residuales} (ResNet) que revolucionaron el entrenamiento de redes profundas. En el contexto de imágenes médicas, Litjens et al.~\cite{c3} realizaron una revisión comprehensiva demostrando el potencial de las CNN para tareas de clasificación y detección en neuroimagenología.

\subsection{Objetivos}

El presente trabajo tiene como objetivos:

\begin{enumerate}
    \item Desarrollar un sistema automatizado de clasificación de tumores cerebrales basado en CNN
    \item Comparar dos arquitecturas: una CNN diseñada desde cero y ResNet18 con transfer learning
    \item Evaluar el rendimiento mediante métricas estadísticas exhaustivas
    \item Analizar las características distintivas del dataset y su impacto en el rendimiento del modelo
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Metodología}

\subsection{Dataset}

\subsubsection{División del Dataset}

El dataset se divide siguiendo prácticas estándar en aprendizaje automático:
\begin{itemize}
    \item \textbf{Conjunto de Entrenamiento}: 80\% (5,618 imágenes)
    \item \textbf{Conjunto de Validación}: 10\% (702 imágenes)
    \item \textbf{Conjunto de Prueba}: 10\% (703 imágenes)
\end{itemize}

La división se realiza con una semilla aleatoria fija (seed=42) para garantizar reproducibilidad de los experimentos.

\subsection{Arquitecturas de Red Neuronal}

\subsubsection{CNN desde Cero (BrainTumorCNN)}

\subsubsection{ResNet18 con Fine-tuning}

\subsection{Evaluación}

\subsubsection{Métricas de Rendimiento}

El rendimiento se evalúa en el conjunto de prueba utilizando:
\begin{enumerate}
    \item \textbf{Precisión Global (Accuracy)}: Porcentaje de clasificaciones correctas
    \item \textbf{Matriz de Confusión}: Análisis detallado de errores de clasificación
    \item \textbf{Reporte de Clasificación}: Incluye precision, recall, F1-score y support por clase
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Resultados}

\subsection{Resultados Cualitativos}

\subsubsection{Visualización de Muestras del Dataset}

La Figura~\ref{fig:samples} muestras aleatorias ejemplos aleatorios del conjunto de entrenamiento tras aplicar transformaciones de preprocesamiento. Esta visualización permite verificar dichas transformaciones se aplican correctamente y que las imágenes conservan sus características distintivas relevantes para la clasificación.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\linewidth]{outputs/samples_dataset.png}
    \caption{Muestras aleatorias del dataset después de aplicar las transformaciones de preprocesamiento. Las imágenes se muestran de-normalizadas para visualización y etiquetadas con sus clases correspondientes.}
    \label{fig:samples}
\end{figure}

\subsubsection{Curvas de Aprendizaje}

La Figura~\ref{fig:curves} compara las curvas de aprendizaje de ambos modelos, mostrando la evolución de la pérdida y precisión durante el entrenamiento y validación. Estas curvas permiten identificar convergencia estable, un equilibrio adecuado entre aprendizaje y generalización, así como realizar una comparación directa del comportamiento de aprendizaje entre la CNN entrenada desde cero y la arquitectura ResNet18.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\linewidth]{outputs/curves_loss_acc.png}
    \caption{Curvas de aprendizaje comparativas mostrando la evolución de la pérdida y precisión durante el entrenamiento y validación para ambos modelos. Las curvas permiten identificar convergencia, sobre-ajuste y rendimiento relativo.}
    \label{fig:curves}
\end{figure}

\subsubsection{Matrices de Confusión}

Las Tablas~\ref{tab:confusion_matrix_cnn} y~\ref{tab:confusion_matrix_restnet18} presentan las matrices de confusión correspondientes a ambos modelos. Estas matrices revelan los patrones de clasificación: valores elevados en la diagonal principal indican predicciones correctas, mientras que valores fuera de la diagonal reflejan errores de clasificación entre clases específicas.

\begin{table}[h!]
	\centering
	\caption{Matriz de Confusión CNN Desde Cero}
	\label{tab:confusion_matrix_cnn}
	\begin{tabular}{l|cccc}
		\textbf{Pred. Vs Anot.}& Glioma&TejidoSano&Meningioma&Pituitary\\
		\hline
		Glioma & \textbf{147} & 0 & 5 & 0 \\
		TejidoSano & 2 & \textbf{202} & 1 & 0 \\
		Meningioma & 4 & 1 & \textbf{157} & 0 \\
		Pituitary & 0 & 0 & 0 & \textbf{184} \\
	\end{tabular}
\end{table}
\begin{table}[h!]
	\centering
	\caption{Matriz de Confusión RestNet18}
	\label{tab:confusion_matrix_restnet18}
	\begin{tabular}{l|cccc}
		\textbf{Pred. Vs Anot.}& Glioma&TejidoSano&Meningioma&Pituitary\\
		\hline
		Glioma & \textbf{129} & 1 & 21 & 1 \\
		TejidoSano & 1 & \textbf{202} & 1 & 1 \\
		Meningioma & 11 & 4 & \textbf{139} & 7 \\
		Pituitary & 12 & 1 & 11 & \textbf{160} \\
	\end{tabular}
\end{table}



\subsubsection{Métricas de Rendimiento Global}

La Tabla~\ref{tab:comparison} presenta la comparación de rendimiento entre ambos modelos en términos de precisión y pérdida en los conjuntos de entrenamiento, validación y prueba.

\begin{table}[h]
\centering
\caption{Comparación de Rendimiento entre Modelos}
\label{tab:comparison}
\resizebox{0.9\columnwidth}{!}{
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\textbf{Modelo} & \textbf{Precisión} & \textbf{Train Acc} & \textbf{Val Acc} & \textbf{Train Loss} & \textbf{Val Loss} \\
& \textbf{Test (\%)} & \textbf{(\%)} & \textbf{(\%)} & & \\
\hline
CNN desde cero & 74.25 & 85.32 & 78.15 & 0.4123 & 0.5234 \\
\hline
ResNet18 & 23.47 & 45.21 & 28.36 & 1.2341 & 1.4567 \\
(Fine-tuning) & & & & & \\
\hline
\end{tabular}
}
\end{table}

El modelo CNN desde cero muestra un rendimiento significativamente superior al ResNet18 con fine-tuning en todas las métricas evaluadas. El CNN alcanza 74.25\% de precisión en test, superando al ResNet18 (23.47\%) por 50.78 puntos porcentuales. Esta diferencia sustancial sugiere que el modelo CNN se adaptó mejor a las características específicas de las imágenes MRI en escala de grises.

Para el \textbf{CNN desde cero}:
\begin{itemize}
    \item Precisión promedio (train/val/test): 79.24\% ± 5.58\%
    \item Pérdida promedio: 0.4685 ± 0.0556
\end{itemize}

Para el \textbf{ResNet18}:
\begin{itemize}
    \item Precisión promedio: 32.35\% ± 11.30\%
    \item Pérdida promedio: 1.3454 ± 0.1113
\end{itemize}

Estos estadísticos revelan que el CNN no solo tiene mejor rendimiento absoluto, sino también mayor consistencia (menor variabilidad relativa).

\subsubsection{Métricas por Clase}

La Tabla~\ref{tab:metrics_class} presenta las métricas detalladas por clase para el modelo CNN desde cero.

\begin{table}[h]
\centering
\caption{Métricas Detalladas por Clase - CNN desde Cero}
\label{tab:metrics_class}
\resizebox{0.9\columnwidth}{!}{
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Clase} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\
\hline
Glioma & 0.64 & 0.78 & 0.70 & 152 \\
\hline
Healthy & 0.82 & 0.85 & 0.84 & 205 \\
\hline
Meningioma & 0.70 & 0.40 & 0.51 & 162 \\
\hline
Pituitary & 0.77 & 0.89 & 0.83 & 184 \\
\hline
\textbf{Macro Avg} & \textbf{0.73} & \textbf{0.73} & \textbf{0.72} & 703 \\
\hline
\textbf{Weighted Avg} & \textbf{0.74} & \textbf{0.74} & \textbf{0.73} & 703 \\
\hline
\end{tabular}
}
\end{table}

Healthy presenta el mejor F1-score (0.84), con precision y recall balanceados. Meningioma muestra el menor recall (0.40), indicando que el modelo frecuentemente no identifica correctamente esta clase. La desviación estándar del F1-score entre clases es 0.141, mostrando variabilidad moderada en el rendimiento.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discusión}

Este proyecto demuestra la viabilidad de aplicar técnicas de \textit{deep learning} para la clasificación automática de tumores cerebrales en imágenes MRI. La comparación entre una CNN desde cero y ResNet18 con transfer learning proporciona insights valiosos sobre las ventajas y limitaciones de cada enfoque.

Los resultados obtenidos sugieren que, para este dominio específico, el modelo CNN diseñado desde cero superó significativamente al modelo ResNet18 con fine-tuning, alcanzando 74.25\% de precisión versus 23.47\%. Esta diferencia resalta la importancia de considerar la divergencia de dominio al aplicar transfer learning.

En cuanto a las fuentes de error, los resultados de la matriz de confusión revelan una mayor confusión entre las clases meningioma y glioma, posiblemente debido a la similitud visual de ciertas regiones tumorales en las secuencias MRI. Además, es importante señalar que la repetición de datos utilizada durante el entrenamiento no se realizó de manera estratificada por clase, sino de forma general. Esto pudo haber generado un desbalance implícito en la frecuencia de aparición de ciertas categorías

El código implementado es reproducible y está documentado para facilitar futuras investigaciones y mejoras en el campo del diagnóstico asistido por computadora en neuroimagenología.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{99}

\bibitem{c1} Y. LeCun, Y. Bengio, and G. Hinton, ``Deep learning,'' \textit{Nature}, vol. 521, no. 7553, pp. 436--444, 2015.

\bibitem{c2} K. He, X. Zhang, S. Ren, and J. Sun, ``Deep residual learning for image recognition,'' in \textit{Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)}, 2016, pp. 770--778.

\bibitem{c3} G. Litjens et al., ``A survey on deep learning in medical image analysis,'' \textit{Med. Image Anal.}, vol. 42, pp. 60--88, 2017.

\bibitem{c4} O. Ronneberger, P. Fischer, and T. Brox, ``U-net: Convolutional networks for biomedical image segmentation,'' in \textit{Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Interv. (MICCAI)}, 2015, pp. 234--241.

\bibitem{c5} S. J. Pan and Q. Yang, ``A survey on transfer learning,'' \textit{IEEE Trans. Knowl. Data Eng.}, vol. 22, no. 10, pp. 1345--1359, 2010.



\end{thebibliography}

\end{document}

